# Exploration

# Notebooks
## deep-image-retrieval
Calculate feature vectors and perform image retrieval using the given code:

**Setup:**
- Clone the DIR repository https://github.com/naver/deep-image-retrieval into a folder named `deep-image-retrieval-repo`.
- Download the Resnet101-AP-GeM-LM18 model from https://github.com/naver/deep-image-retrieval/#pre-trained-models and place it under `deep-image-retrieval-repo/dirtorch/models/Resnet101-AP-GeM-LM18.pt`

**Calculating the feature vectors:**
- Place the images in the dataset into a folder
- Create a textfile that lists all the images in the image folder
- Run the command for computing feature vectors indicated on the repo https://github.com/naver/deep-image-retrieval/#reproducing-the-results

Steps 2 and 3 can be automated by using the notebook `notebooks/get_features.ipynb`.

The command in step 3 will output a numpy matrix file (.npy) of size (number of images in dataset, 2048)

**Calculating image similarity:**

To compare feature vectors of two images we can simply compare their cosine distances. Images are accessed by their index in the image set.

Below is outlined how to calculate the similarity between image a (index x) and image b (index y). This is assuming the feature vectors of both images are stored in the feature vector matrix 
- Read the feature vectors in the .npy file
- Get the feature vectors as feature\_a = features[x] and feature\_b = features[y]
- Calculate the cosine distance via the dot product: `feature_a  * feature_b`

Image retrieval via image similarity can be performed using the notebook under `notebooks/DeepImageRetrieval.ipynb`.

For the Hamburg dataset we found that a minimum cosine distance between 0.1 and 0.2 indicates that both images show the same landmark. For different datasets the minimum cosine distance may vary. 

## hashtag-retrieval
Perform image retrieval via regex expressions on image meta-data, for example hashtags and captions.

## heatmaps
Generate heatmaps based on frequency data.

The data under `hamburg19_flickr_test_latlong.csv` was generated using the Cloud Vision API landmark detection service on the Hamburg 2019 test set (5000 images).

The data under `hamburg22_occurences.csv` was generated by performing image retrieval with DIR on the Hamburg 2009, 2014 and 2019 datasets.

A tutorial for how to generate the data via deep image retrieval as was done for `hamburg22_occurences.csv` is given at `Heatmap Generation Documentation.pdf`